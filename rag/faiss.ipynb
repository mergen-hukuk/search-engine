{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"climate change\",\n",
    "    \"quantum computing\",\n",
    "    \"renaissance art\",\n",
    "    \"neuroscience\",\n",
    "    \"cryptocurrency\",\n",
    "    \"medieval history\",\n",
    "    \"oceanography\",\n",
    "    \"robotics\",\n",
    "    \"classical music\",\n",
    "    \"genetic engineering\",\n",
    "    \"bethoven\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = model.encode(documents, convert_to_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to float32 NumPy array\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Initialize a Faiss index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance (Euclidean)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x32eac2430> >\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: sun and ice and melting\n",
      "\n",
      "Top 3 most similar sentences in the corpus:\n",
      "1. climate change (Distance: 1.0630)\n",
      "2. cryptocurrency (Distance: 1.5013)\n",
      "3. oceanography (Distance: 1.6184)\n",
      "4. classical music (Distance: 1.7625)\n",
      "5. renaissance art (Distance: 1.7873)\n",
      "6. robotics (Distance: 1.8202)\n",
      "7. medieval history (Distance: 1.8522)\n",
      "8. bethoven (Distance: 1.8590)\n",
      "9. quantum computing (Distance: 1.8774)\n",
      "10. neuroscience (Distance: 1.9257)\n"
     ]
    }
   ],
   "source": [
    "# Define a query sentence\n",
    "query = \"sun and ice and melting\"\n",
    "\n",
    "# Compute the embedding for the query\n",
    "query_embedding = model.encode([query], convert_to_tensor=False).astype('float32')\n",
    "\n",
    "# Search the index for the top 3 most similar sentences\n",
    "k = 10\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Display the results\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nTop 3 most similar sentences in the corpus:\")\n",
    "\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"{i+1}. {documents[idx]} (Distance: {distances[0][i]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
